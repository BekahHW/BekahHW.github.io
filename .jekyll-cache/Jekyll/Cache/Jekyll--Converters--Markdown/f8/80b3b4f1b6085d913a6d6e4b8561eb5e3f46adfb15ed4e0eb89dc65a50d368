I"á"<p>Models allow us to take data and make predictions, reactions, transformations, etc. There are models that work with images, audio, and other forms of data. We can do things like identify objects in images, create text from audio, and analyze the form of athletes doing things like swinging a baseball bat, doing a deadlift, or throwing a ball.</p>

<p>Creating your own model might sound really overwhelming and impossible if you‚Äôre just learning TFJS. And that‚Äôs ok! You don‚Äôt have to create your own models. You can work with a pre-trained model and run it as is, or you can train it for your specific uses‚Äìalso known as <strong><a href="https://builtin.com/data-science/transfer-learning">transfer learning</a></strong>. Today, we‚Äôre going to be talking about using pretrained models and how you can do that.</p>

<h3 id="words-to-know">Words to Know</h3>

<p><strong>Model</strong>: an expression of an algorithm that‚Äôs been trained with data to recognize patterns and can make predictions, transformations, or react.
<strong><a href="https://tfhub.dev/">TFHub</a></strong>: TensorFlow Hub is a Google site that hosts popular community models that anyone can use.
<strong>Image Classification</strong>: when a trained model identifies images and labels them.</p>

<p>When you‚Äôre getting started with TFJS models, you need to decide what kind of model you need and where you can access that model. We‚Äôre not going to go in depth into the difference between Layers models and Graph models, because we‚Äôre going to focus on how to use models and then come back to that in a future blog post once we get a better sense of how we‚Äôre using models. But it‚Äôs worth mentioning here in case you‚Äôre ready to jump in and do some research on your own. If you‚Äôre looking at examples, you might notice that some models are loaded using the <a href="https://js.tensorflow.org/api/latest/#loadLayersModel">loadLayersModel method</a> for Layers models or <a href="https://js.tensorflow.org/api/latest/#loadGraphModel">the loadGraphModel method</a> for Graph Models.</p>

<h2 id="using-a-model-from-tfhub">Using a Model from TFHub</h2>

<p>When we got to <a href="https://tfhub.dev/">TFHub</a> we see there are a number of options to choose from. Since I‚Äôm learning TensorFlow.js, I like to start by browsing the <code class="language-plaintext highlighter-rouge">Model format</code> category for <code class="language-plaintext highlighter-rouge">TF.js</code>.</p>

<p>From there, you can narrow it down further by looking at the TF Version, whether or not it‚Äôs Fine Tunable, Architecture, Publisher, Dataset, or language. We‚Äôre going to take a look at <code class="language-plaintext highlighter-rouge">Architecture</code> &gt; <code class="language-plaintext highlighter-rouge">Inception V3</code>.</p>

<p>That leaves us <a href="https://tfhub.dev/s?deployment-format=tfjs&amp;network-architecture=inception-v3">with three options</a>. Well, since one of our terms for today was image classification, I bet you can guess that <code class="language-plaintext highlighter-rouge">[Image Classification](https://tfhub.dev/google/imagenet/inception_v3/classification/5)</code> is our selection.</p>

<p>We need to identify what‚Äôs most important here. We need to know the size of the image that‚Äôs expected, the image values, ranging from 0 to 1. And finally, we‚Äôre looking for the values that are returned. This image classifier is going to identify how likely an image is related to the labels. Let‚Äôs take a look at the <a href="download.tensorflow.org/data/ImageNetLabels.txt">labels</a> they give us.</p>

<p>It‚Äôs important to note that we‚Äôre going to give the labels their own file in our example, and export them as ‚ÄúINCEPTION_CLASSES‚Äù</p>

<p>These are the names for the images the model is trained to identify and will return numbers that relate to certaintly for each of the labels. For example, if we show the model a picture of a kitten, and that returns .9800 for the cat label, then it is 98% sure that the kitten is a cat.</p>

<p>(If you really want cuteness, check out the <a href="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSH34JAxPLqDvnWvnDmc5qubBHzmjMvkiWQ2bJJl2V_yEMIQIAjno5Ltq9tfjqVgIS3uFc&amp;usqp=CAU">axolotl</a>. That‚Äôs my fav on the list.)</p>

<p>Now the <a href="https://tfhub.dev/google/tfjs-model/imagenet/inception_v3/classification/3/default/1">page for v3</a> of this model tells us that we need to load the model like this:</p>

<p><code class="language-plaintext highlighter-rouge">tf.loadGraphModel("https://tfhub.dev/google/tfjs-model/imagenet/inception_v3/classification/3/default/1", { fromTFHub: true })</code></p>

<p>But once we load that model, then what? Let‚Äôs dig into how to use the model.</p>

<p>Well, the model classifies, right? That means that we need to give it something to classify.</p>

<p>So there are two things we need to do here.</p>

<p>Get the image
Put the image in a usable form.</p>

<p>So let‚Äôs imagine that we have an image in our <code class="language-plaintext highlighter-rouge">index.html</code> file that looks like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;img
        id="inceptionImg"
        src="https://source.unsplash.com/YeOMRwgvPv4"
        crossorigin="anonymous"
        style="width: 50%;"
      /&gt;
</code></pre></div></div>

<p>So let‚Äôs grab that using jQuery:</p>

<p><code class="language-plaintext highlighter-rouge">const lobsterImg = document.getElementById("inceptionImg");</code></p>

<p>Now that we have the image, we need to convert it to a usable form. This means we need to convert it from pixels into tensors, and then we need to make it the correct shape.</p>

<p>In this case, <a href="https://tfhub.dev/google/imagenet/inception_v3/classification/5">the docs</a> give us the size we need:</p>

<blockquote>
  <p>The expected size of the input images is height x width = 299 x 299 pixels by default, but other input sizes are possible (within limits).</p>
</blockquote>

<p><strong><a href="https://js.tensorflow.org/api/latest/#browser.fromPixels">Pixels to Tensors</a></strong>
<code class="language-plaintext highlighter-rouge">const tensorLobster= tf.browser.fromPixels(lobsterImg);</code></p>

<p><strong><a href="https://js.tensorflow.org/api/latest/#image.resizeBilinear">Resize Image</a></strong></p>

<p>This is going to be a three-step process. We need to resize and reshape:</p>

<p><code class="language-plaintext highlighter-rouge">const formattedImg = tf.image.resizeBilinear(tensorLobster, [299, 299], true).div(255).reshape([1, 299, 299, 3])</code></p>

<p>That gives us a form that we can work with to find the results.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>const results = model.predict(formattedImg)
result.print( )
</code></pre></div></div>

<p>What do we see in the console? We need to do a little bit more work to get this into a form we can use. So we‚Äôre going to look at the <a href="https://js.tensorflow.org/api/latest/#div">topk method</a>. What we see from the docs is that this method:</p>

<blockquote>
  <p>Finds the values and indices of the k largest entries along the last dimension.</p>
</blockquote>

<p>We‚Äôre going to pass it our results and limit it to the top 3 values. For that, we want to use indices.</p>

<p><code class="language-plaintext highlighter-rouge">const { values, indices } = tf.topk(results, 3)</code></p>

<p>Now we can access the top three labels that this model has used to classify our image. Remember those INCEPTION_CLASSES we referred to earlier in the post? We need to use those now like this if we‚Äôre console.logging it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"first place:", INCEPTION_CLASSES[winners[0]],
"second place:", INCEPTION_CLASSES[winners[1]],
"Third place:", INCEPTION_CLASSES[winners[2]]
</code></pre></div></div>

<p>You can console.log this, or you can check out the <a href="https://codesandbox.io/s/inception-tfjs-sandbox-rcor8?file=/src/index.js:1150-1320">codesandbox</a> I made, and click the run button to see the top three labels render to the screen.</p>

<p>And that‚Äôs it! That‚Äôs how we can use this model. If you‚Äôre learning along with me, please feel free to ask questions, check out my <a href="https://www.twitch.tv/bekahhw/">twitch stream</a> where I talk through all these concepts, sign-up for our <a href="https://lu.ma/z1vbo6jc">study group</a>, and remember that we‚Äôre jumping past some of the basics to have some fun, but we‚Äôre making up for that along the way. It might not be a traditional path, but it‚Äôs one that works for me and, hopefully, for you.</p>
:ET